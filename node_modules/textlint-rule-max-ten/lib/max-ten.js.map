{"version":3,"sources":["../src/max-ten.js"],"names":["defaultOptions","max","strict","touten","kuten","isSandwichedMeishi","before","token","after","undefined","pos","is括弧","test","pos_detail_1","surface_form","findSiblingMeaningToken","tokens","currentIndex","direction","delta","sibilingToken","module","exports","context","options","maxLen","isStrict","helper","RuleHelper","Syntax","RuleError","report","getSource","separatorCharacters","concat","Paragraph","node","isChildNode","BlockQuote","resultNode","SeparatorParser","sentences","children","filter","childNode","type","SentenceSyntax","Sentence","checkSentence","sentence","source","StringSource","replacer","maskValue","Code","text","toString","currentTenCount","lastToken","forEach","index","surface","isSandwiched","includes","positionInSentence","originalIndexFromIndex","word_position","range","ruleError","Promise","all","map"],"mappings":"AAAA;AACA;;AACA;;AACA;;AACA;;AACA;;;;;;AAEA,IAAMA,cAAc,GAAG;AACnB;AACAC,EAAAA,GAAG,EAAE,CAFc;AAGnB;AACAC,EAAAA,MAAM,EAAE,KAJW;AAKnB;AACA;AACAC,EAAAA,MAAM,EAAE,GAPW;AAQnB;AACA;AACAC,EAAAA,KAAK,EAAE;AAVY,CAAvB;;AAaA,SAASC,kBAAT,OAAsD;AAAA,MAA1B;AAAEC,IAAAA,MAAF;AAAUC,IAAAA,KAAV;AAAiBC,IAAAA;AAAjB,GAA0B;;AAClD,MAAIF,MAAM,KAAKG,SAAX,IAAwBD,KAAK,KAAKC,SAAlC,IAA+CF,KAAK,KAAKE,SAA7D,EAAwE;AACpE,WAAO,KAAP;AACH;;AACD,SAAOH,MAAM,CAACI,GAAP,KAAe,IAAf,IAAuBF,KAAK,CAACE,GAAN,KAAc,IAA5C;AACH;AAED;AACA;AACA;AACA;AACA;;;AACA,SAASC,IAAT,CAAcJ,KAAd,EAAqB;AACjB,MAAIA,KAAK,CAACG,GAAN,KAAc,IAAd,IAAsB,MAAME,IAAN,CAAWL,KAAK,CAACM,YAAjB,CAA1B,EAA0D;AACtD,WAAO,IAAP;AACH;;AACD,MAAIN,KAAK,CAACO,YAAN,KAAuB,GAAvB,IAA8BP,KAAK,CAACO,YAAN,KAAuB,GAAzD,EAA8D;AAC1D,WAAO,IAAP;AACH;;AACD,SAAO,KAAP;AACH;AAED;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;AACA,SAASC,uBAAT,QAAsE;AAAA,MAArC;AAAEC,IAAAA,MAAF;AAAUC,IAAAA,YAAV;AAAwBC,IAAAA;AAAxB,GAAqC;AAClE,MAAMC,KAAK,GAAGD,SAAS,KAAK,MAAd,GAAuB,CAAC,CAAxB,GAA4B,CAA1C;AACA,MAAME,aAAa,GAAGJ,MAAM,CAACC,YAAY,GAAGE,KAAhB,CAA5B;;AACA,MAAI,CAACC,aAAL,EAAoB;AAChB;AACH,GALiE,CAMlE;;;AACA,MAAIT,IAAI,CAACS,aAAD,CAAR,EAAyB;AACrB,WAAOL,uBAAuB,CAAC;AAC3BC,MAAAA,MAD2B;AAE3BC,MAAAA,YAAY,EAAEA,YAAY,GAAGE,KAFF;AAG3BD,MAAAA;AAH2B,KAAD,CAA9B;AAKH;;AACD,SAAOE,aAAP;AACH;AAED;AACA;AACA;AACA;;;AACAC,MAAM,CAACC,OAAP,GAAiB,UAAUC,OAAV,EAAiC;AAAA;;AAAA,MAAdC,OAAc,uEAAJ,EAAI;AAC9C,MAAMC,MAAM,mBAAGD,OAAO,CAACvB,GAAX,uDAAkBD,cAAc,CAACC,GAA7C;AACA,MAAMyB,QAAQ,sBAAGF,OAAO,CAACtB,MAAX,6DAAqBF,cAAc,CAACE,MAAlD;AACA,MAAMC,MAAM,sBAAGqB,OAAO,CAACrB,MAAX,6DAAqBH,cAAc,CAACG,MAAhD;AACA,MAAMC,KAAK,qBAAGoB,OAAO,CAACpB,KAAX,2DAAoBJ,cAAc,CAACI,KAA9C;AACA,MAAMuB,MAAM,GAAG,IAAIC,8BAAJ,CAAeL,OAAf,CAAf;AACA,MAAM;AAAEM,IAAAA,MAAF;AAAUC,IAAAA,SAAV;AAAqBC,IAAAA,MAArB;AAA6BC,IAAAA;AAA7B,MAA2CT,OAAjD;AACA,MAAMU,mBAAmB,GAAG,CACxB,GADwB,EACnB;AACL,KAFwB,EAEnB;AACL,KAHwB,EAGnB;AACL,KAJwB,CAIpB;AAJoB,IAK1BC,MAL0B,CAKnB9B,KALmB,CAA5B;AAMA,SAAO;AACH,KAACyB,MAAM,CAACM,SAAR,EAAmBC,IAAnB,EAAyB;AACrB,UAAIT,MAAM,CAACU,WAAP,CAAmBD,IAAnB,EAAyB,CAACP,MAAM,CAACS,UAAR,CAAzB,CAAJ,EAAmD;AAC/C;AACH;;AACD,UAAMC,UAAU,GAAG,gCAASH,IAAT,EAAe;AAC9BI,QAAAA,eAAe,EAAE;AACbP,UAAAA,mBAAmB,EAAEA;AADR;AADa,OAAf,CAAnB;AAKA,UAAMQ,SAAS,GAAGF,UAAU,CAACG,QAAX,CAAoBC,MAApB,CAA4BC,SAAD,IAAeA,SAAS,CAACC,IAAV,KAAmBC,yBAAeC,QAA5E,CAAlB;AACA;AACZ;AACA;AACA;AACA;AACA;;AACY;AACZ;AACA;AACA;AACA;AACA;;AACY,UAAMC,aAAa;AAAA,sCAAG,WAAOC,QAAP,EAAoB;AACtC,cAAMC,MAAM,GAAG,IAAIC,kCAAJ,CAAiBF,QAAjB,EAA2B;AACtCG,YAAAA,QAAQ,QAAsB;AAAA,kBAArB;AAAEhB,gBAAAA,IAAF;AAAQiB,gBAAAA;AAAR,eAAqB;;AAC1B,kBAAIjB,IAAI,CAACS,IAAL,KAAchB,MAAM,CAACyB,IAAzB,EAA+B;AAC3B,uBAAOD,SAAS,CAAC,GAAD,CAAhB;AACH;AACJ;;AALqC,WAA3B,CAAf;AAOA,cAAME,IAAI,GAAGL,MAAM,CAACM,QAAP,EAAb;AACA,cAAMxC,MAAM,SAAS,yBAASuC,IAAT,CAArB;AACA,cAAIE,eAAe,GAAG,CAAtB;AACA,cAAIC,SAAS,GAAG,IAAhB;AACA1C,UAAAA,MAAM,CAAC2C,OAAP,CAAe,CAACpD,KAAD,EAAQqD,KAAR,KAAkB;AAC7B,gBAAMC,OAAO,GAAGtD,KAAK,CAACO,YAAtB;;AACA,gBAAI+C,OAAO,KAAK1D,MAAhB,EAAwB;AACpB;AACA,kBAAM2D,YAAY,GAAGzD,kBAAkB,CAAC;AACpCC,gBAAAA,MAAM,EAAES,uBAAuB,CAAC;AAC5BC,kBAAAA,MAD4B;AAE5BC,kBAAAA,YAAY,EAAE2C,KAFc;AAG5B1C,kBAAAA,SAAS,EAAE;AAHiB,iBAAD,CADK;AAMpCX,gBAAAA,KAAK,EAAEA,KAN6B;AAOpCC,gBAAAA,KAAK,EAAEO,uBAAuB,CAAC;AAC3BC,kBAAAA,MAD2B;AAE3BC,kBAAAA,YAAY,EAAE2C,KAFa;AAG3B1C,kBAAAA,SAAS,EAAE;AAHgB,iBAAD;AAPM,eAAD,CAAvC,CAFoB,CAepB;;AACA,kBAAI,CAACQ,QAAD,IAAaoC,YAAjB,EAA+B;AAC3B;AACH;;AACDL,cAAAA,eAAe;AACfC,cAAAA,SAAS,GAAGnD,KAAZ;AACH;;AACD,gBAAI0B,mBAAmB,CAAC8B,QAApB,CAA6BF,OAA7B,CAAJ,EAA2C;AACvC;AACAJ,cAAAA,eAAe,GAAG,CAAlB;AACH,aA3B4B,CA4B7B;;;AACA,gBAAIA,eAAe,GAAGhC,MAAtB,EAA8B;AAC1B,kBAAMuC,kBAAkB,GAAGd,MAAM,CAACe,sBAAP,CAA8BP,SAAS,CAACQ,aAAV,GAA0B,CAAxD,CAA3B,CAD0B,CAE1B;AACA;;AACA,kBAAMN,MAAK,GAAGX,QAAQ,CAACkB,KAAT,CAAe,CAAf,IAAoB/B,IAAI,CAAC+B,KAAL,CAAW,CAAX,CAApB,GAAoCH,kBAAlD;;AACA,kBAAMI,SAAS,GAAG,IAAI7C,OAAO,CAACO,SAAZ,2CACL3B,MADK,qBACMsB,MAAM,GAAG,CADf,mEAEd;AACImC,gBAAAA,KAAK,EAALA;AADJ,eAFc,CAAlB;AAMA7B,cAAAA,MAAM,CAACK,IAAD,EAAOgC,SAAP,CAAN;AACAX,cAAAA,eAAe,GAAG,CAAlB;AACH;AACJ,WA3CD;AA4CH,SAxDkB;;AAAA,wBAAbT,aAAa;AAAA;AAAA;AAAA,SAAnB;;AAyDA,aAAOqB,OAAO,CAACC,GAAR,CAAY7B,SAAS,CAAC8B,GAAV,CAAcvB,aAAd,CAAZ,CAAP;AACH;;AAjFE,GAAP;AAmFH,CAhGD","sourcesContent":["// LICENSE : MIT\n\"use strict\";\nimport { RuleHelper } from \"textlint-rule-helper\";\nimport { tokenize } from \"kuromojin\";\nimport { splitAST, Syntax as SentenceSyntax } from \"sentence-splitter\";\nimport { StringSource } from \"textlint-util-to-string\";\n\nconst defaultOptions = {\n    // 1文に利用できる最大の、の数\n    max: 3,\n    // 例外ルールを適応するかどうか,\n    strict: false,\n    // 読点として扱う文字\n    // https://ja.wikipedia.org/wiki/%E8%AA%AD%E7%82%B9\n    touten: \"、\",\n    // 句点として扱う文字\n    // https://ja.wikipedia.org/wiki/%E5%8F%A5%E7%82%B9\n    kuten: \"。\"\n};\n\nfunction isSandwichedMeishi({ before, token, after }) {\n    if (before === undefined || after === undefined || token === undefined) {\n        return false;\n    }\n    return before.pos === \"名詞\" && after.pos === \"名詞\";\n}\n\n/**\n * 括弧のトークンかどうか\n * @param token\n * @returns {boolean}\n */\nfunction is括弧(token) {\n    if (token.pos === \"記号\" && /^括弧/.test(token.pos_detail_1)) {\n        return true;\n    }\n    if (token.surface_form === \"(\" || token.surface_form === \")\") {\n        return true;\n    }\n    return false;\n}\n\n/**\n * 括弧などの記号的なTokenはスキップとして隣接するTokenを探す\n * @see https://github.com/textlint-ja/textlint-rule-max-ten/issues/12\n * @param {*[]} tokens\n * @param {number} currentIndex\n * @param {\"prev\"|\"next\"} direction\n * @returns {undefined | *}\n */\nfunction findSiblingMeaningToken({ tokens, currentIndex, direction }) {\n    const delta = direction === \"prev\" ? -1 : 1;\n    const sibilingToken = tokens[currentIndex + delta];\n    if (!sibilingToken) {\n        return;\n    }\n    // 括弧はスキップして、隣接Nodeを探す\n    if (is括弧(sibilingToken)) {\n        return findSiblingMeaningToken({\n            tokens,\n            currentIndex: currentIndex + delta,\n            direction\n        });\n    }\n    return sibilingToken;\n}\n\n/**\n * @param {RuleContext} context\n * @param {typeof defaultOptions} [options]\n */\nmodule.exports = function (context, options = {}) {\n    const maxLen = options.max ?? defaultOptions.max;\n    const isStrict = options.strict ?? defaultOptions.strict;\n    const touten = options.touten ?? defaultOptions.touten;\n    const kuten = options.kuten ?? defaultOptions.kuten;\n    const helper = new RuleHelper(context);\n    const { Syntax, RuleError, report, getSource } = context;\n    const separatorCharacters = [\n        \"?\", // question mark\n        \"!\", //  exclamation mark\n        \"？\", // (ja) zenkaku question mark\n        \"！\" // (ja) zenkaku exclamation mark\n    ].concat(kuten);\n    return {\n        [Syntax.Paragraph](node) {\n            if (helper.isChildNode(node, [Syntax.BlockQuote])) {\n                return;\n            }\n            const resultNode = splitAST(node, {\n                SeparatorParser: {\n                    separatorCharacters: separatorCharacters\n                }\n            });\n            const sentences = resultNode.children.filter((childNode) => childNode.type === SentenceSyntax.Sentence);\n            /*\n             <p>\n             <str><code><img><str>\n             <str>\n             </p>\n             */\n            /*\n             # workflow\n             1. split text to sentences\n             2. sentence to tokens\n             3. check tokens\n             */\n            const checkSentence = async (sentence) => {\n                const source = new StringSource(sentence, {\n                    replacer({ node, maskValue }) {\n                        if (node.type === Syntax.Code) {\n                            return maskValue(\"_\");\n                        }\n                    }\n                });\n                const text = source.toString();\n                const tokens = await tokenize(text);\n                let currentTenCount = 0;\n                let lastToken = null;\n                tokens.forEach((token, index) => {\n                    const surface = token.surface_form;\n                    if (surface === touten) {\n                        // 名詞に囲まわれている場合は例外とする\n                        const isSandwiched = isSandwichedMeishi({\n                            before: findSiblingMeaningToken({\n                                tokens,\n                                currentIndex: index,\n                                direction: \"prev\"\n                            }),\n                            token: token,\n                            after: findSiblingMeaningToken({\n                                tokens,\n                                currentIndex: index,\n                                direction: \"next\"\n                            })\n                        });\n                        // strictなら例外を例外としない\n                        if (!isStrict && isSandwiched) {\n                            return;\n                        }\n                        currentTenCount++;\n                        lastToken = token;\n                    }\n                    if (separatorCharacters.includes(surface)) {\n                        // reset\n                        currentTenCount = 0;\n                    }\n                    // report\n                    if (currentTenCount > maxLen) {\n                        const positionInSentence = source.originalIndexFromIndex(lastToken.word_position - 1);\n                        // relative index from Paragraph Node\n                        // Sentence start(relative) + word position(relative)\n                        const index = sentence.range[0] - node.range[0] + positionInSentence;\n                        const ruleError = new context.RuleError(\n                            `一つの文で\"${touten}\"を${maxLen + 1}つ以上使用しています`,\n                            {\n                                index\n                            }\n                        );\n                        report(node, ruleError);\n                        currentTenCount = 0;\n                    }\n                });\n            };\n            return Promise.all(sentences.map(checkSentence));\n        }\n    };\n};\n"],"file":"max-ten.js"}